
<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
		<title>Self Supervised Learning: What is Next? - ECCV 2022</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

    <meta property='og:title' content="Self Supervised Learning: What is Next? - ECCV 2022"/>
    <!-- <meta property='og:image' content='http://sightsound.org/dog-sight-sound11.png /> -->    
	</head>
	<body>
		<!-- Wrapper -->
        <div id = "wrapper">
            <!-- Header-->
            <header id="header" class = "alt" style = "width: 100%">
                <!-- <div class = "bgimg" style = "height: 475px">-->
                <div class = "bgimg" style = "height: 250px; width: 100%">
                  <div style = "height: 20px; width: 100%"></div>
                  <h1 style = "text-shadow: 0.1px 0.1px #000000">Self Supervised Learning: What is Next?</h1>
                  <h2 style = "text-shadow: 0.1px 0.1px #000000">ECCV 2022</h2>
                </div>
            </header>

            <!-- Nav -->
            <nav id="nav">
                <ul>
                    <li><a href="#intro" class="active">Introduction</a></li>
                    <!-- <li><a href="#videos">Videos</a></li> -->
                    <li><a href="#cfp">Call for Papers</a></li>
                    <li><a href="#speakers">Speakers</a></li>
                    <li><a href="#info">Organizers</a></li>
                    <li><a href="index2020.html">ECCV 2020</a></li>
                </ul>
            </nav>

            <!-- Main -->
            <div id="main">
                <!-- Introduction -->
                <section id="intro" class="main">
                    <header class="major" style="text-align:center">
                        <h2>Summary</h2>
                    </header>
                    <div class="spotlight" style = "width: 90%">
                        <div class="content">
                            <p>
                                The past two years have seen major advances in self-supervised learning, with many new methods reaching astounding performances on standard benchmarks. Moreover, many recent works have shown the large potential of coupled data sources such as image-text in producing even stronger models capable of zero-shot tasks, and often inspired by NLP.
                                We have just witnessed a jump from the "default" single-modal pretraining with CNNs to Transformer-based multi-modal training, and these early developments will surely mature in the coming months. 
                                However, despite this it is also apparent that there are still major unresolved challenges and it is not clear what the next step-change is going to be. 
                                In this workshop we want to highlight and provide a forum to discuss potential research direction seeds, from radically new self-supervision tasks, data sources and paradigms to surprising counter-intuitive results.
                                Through invited speakers and paper oral talks, our goal is to provide a forum to discuss and exchange ideas where both the leaders in this field, as well as the new, younger generation can equally contribute to discussing the future of this field.
                            </p>
                            <p>
                                A major goal of unsupervised learning in computer vision is to learn general data representations without labels. 
                                For this, countless pretext tasks such as image colorization and more recently contrastive learning and teacher-student approaches have been proposed to learn neural networks for feature extraction. 
                                While these methods are rapidly improving in performance and have surpassed supervised representations on many downstream tasks, many challenges remain and the ``next big step'' is not apparent.
                            </p>
                            <p>
                                As the methods are maturing, the field is now at the point where we have to start discussing how we can make optimal use of self-supervised representations in applications, as well as what are the remaining obstacles and possible approaches to tackle them.
                                The workshop aims to give space to ask and discuss fundamental, longer-term questions with  researchers that are leading this area.
                                Key questions we aim to tackle include:
                                <ul>
                                    <li>What are the current bottlenecks in self-supervised learning?</li>
                                    <li>What is the future role of weak supervision, like image-text and video+ASR?</li>
                                    <li>What can never be learned purely from self-supervision?</li>
                                    <li>How many modalities do we need for true robustness and understanding?</li>
                                    <li>What is the fundamental role of data augmentation?</li>
                                    <li>Which kind of bias may be captured in the resulting models, and what does this imply?</li>
                                </ul>
                            </p>
                            <p>
                                This is the second iteration of the SSL-WIN workshop. The workshop will be organized as a hybrid full-day event where a series of invited speakers and oral talks from the submitted papers will present their views on how the field needs to evolve in the coming years. 
                            </p>
                        </div>
                    </div>
                </section>

                <section id="cfp" class="main">
                    <header class="major" style="text-align:center">
                        <h2>Call for Papers</h2>
                    </header>
                    <div class="spotlight" style = "width: 90%">
                        <div class="content">
                            <p>
                                We invite submissions of full papers with original ideas of unpublished work or position papers. Accepted papers after peer-review will be published in the ECVA online proceedings and Springer printed proceedings. For this reason, paper submissions will adhere to the <a href="https://eccv2022.ecva.net/submission/call-for-papers/">ECCV 2022 paper submission style, format, and length restrictions</a>.
                            </p>
                            <p>
                                <ul style="list-style-type:none;">
                                <li><strong>Submission:</strong> July 6th, 2022, 11:59 PST via <a href="https://cmt3.research.microsoft.com/SSLWIN2022">via CMT</a></li>
                                <li><strong>Review period:</strong> July 15, 2022 - August 15, 2022</li>
                                <li><strong>Notification of acceptance:</strong> August 18, 2022</li>
                                <li><strong>Camera ready:</strong> August 22nd </li>
                                <li><strong>Workshop:</strong> October 23-24 (day TBD)</li>
                                </ul>
                            </p> 
                                If you would like to volunteer as a reviewer, please fill in <a href="https://forms.gle/589o1zKBbRddpDx68">this short form</a>.
                            </p>
                        </div>
                    </div>
                </section>

                <section id="speakers" class="main special">
                    <header class="major" style="text-align:center">
                        <h2>Tentative List of Speakers</h2>
                    </header>
                    <div class="table-wrapper" style ="width:100%">
                        <table cellpadding = "0" cellspacing = "0">
                            <tr>
                                <td><img class="rounded-img-dark" height="125px" src="photos/alayrac.jpg"><br><a href="https://www.jbalayrac.com/">Jean-Baptiste Alayrac<br>DeepMind</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/caron.jpg"><br><a href="https://scholar.google.com/citations?user=eiB0s-kAAAAJ&hl=fr">Mathilde Caron<br>Google</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/efros.jpg"><br><a href="https://people.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros<br>UC Berkeley</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/misra.jpg"><br><a href="https://imisra.github.io/">Ishan Misra<br>FAIR</a></td> 
                            </tr><tr>
                                <td><img class="rounded-img-dark" height="125px" src="photos/oord.jpg"><br><a href="https://avdnoord.github.io/homepage/">AÃ¤ron van den Oord<br>DeepMind</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/schmid.jpg"><br><a href="https://thoth.inrialpes.fr/~schmid/">Cordelia Schmid<br>Inria Grenoble, Google</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/smith.jpg"><br><a href="https://cogdev.lab.indiana.edu/">Linda Smith<br>Indiana University</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/vedaldi.jpg"><br><a href="https://www.robots.ox.ac.uk/~vedaldi">Andrea Vedaldi<br>University of Oxford</td>
				            </tr>
                        </table>
                    </div>
                </section>
						
                <section id="info" class="main special">
                    <header class="major">
                        <h2>Organizers</h2>
                    </header>
                    <div class="table-wrapper" style ="width:100%">
                        <table cellpadding = "0" cellspacing = "0">
                            <tr>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/asano.jpg"><br><a href = "https://yukimasano.github.io/">Yuki M Asano<br> University of Amsterdam</a></td>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/rupprecht.jpg"><br><a href = "http://chrirupp.github.io">Christian Rupprecht<br>University of Oxford</a></td>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/larlus.jpg"><br><a href = "https://dlarlus.github.io/">Diane Larlus<br>NAVER LABS Europe</a></td>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/zisserman.jpg"><br><a href = "https://www.robots.ox.ac.uk/~az">Andrew Zisserman<br>University of Oxford</td>
                            </tr>
                        </table>
                    </div>
                </section>
            </div>

                 
            <!-- Footer -->
            <footer id="footer">
                <p class = "copyright" style="font-size:medium">
                    Website design adapted from <a href = "http://sightsound.org">sightsound.org</a>
                    and based on a template from <a href="https://html5up.net">HTML5 UP</a>.
                </p>
            </footer>
			</div>

		<!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/util.js"></script>
        <!--[if lte IE 8]>
        <script src="assets/js/ie/respond.min.js"></script><![endif]-->
        <!-- <script src="assets/js/main.js"></script> -->
    <script>
      function convertDateAndTimezone(timeStr) {
        var newDate = new Date("2020-08-28T"+timeStr+":00.000Z");
        return newDate.toString();   
      }
      
	    function convertTime(timeStr) {
        var newDate = new Date("2020-08-28T"+timeStr+":00.000Z");
        return newDate.toLocaleTimeString([], {hour: '2-digit', minute:'2-digit'});   
      }
      
      function convertTimeRange(rangeStr) {
        var s = rangeStr.split('-')
        return convertTime(s[0]) + ' - ' + convertTime(s[1]);   
      }
      
      $( document ).ready(function() {
        $( ".convertTime" ).each(function( index ) {
          $(this).text(convertTime($(this).text()));
        });

        $( ".convertDate" ).each(function( index ) {
          $(this).text(convertDateAndTimezone($(this).text()));
        });

        $( ".convertTimeRange" ).each(function( index ) {
          $(this).text(convertTimeRange($(this).text()));
        });
        
        $( ".collapsible" ).click(function() {
            $(this).toggleClass("active");
            $(this).next().toggle();
        });
      });
	  </script>
	</body>
</html>
