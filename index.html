
<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
<head>
		<title>Self Supervised Learning: What is Next? - ECCV 2020</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="assets/css/main.css" />

    <meta property='og:title' content="Self Supervised Learning: What is Next? - ECCV 2020"/>
    <!-- <meta property='og:image' content='http://sightsound.org/dog-sight-sound11.png /> -->    
	</head>
	<body>
		<!-- Wrapper -->
        <div id = "wrapper">
            <!-- Header-->
            <header id="header" class = "alt" style = "width: 100%">
                <!-- <div class = "bgimg" style = "height: 475px">-->
                <div class = "bgimg" style = "height: 250px; width: 100%">
                  <div style = "height: 20px; width: 100%"></div>
                  <h1 style = "text-shadow: 0.1px 0.1px #000000">Self Supervised Learning: What is Next?</h1>
                  <h2 style = "text-shadow: 0.1px 0.1px #000000">ECCV 2020 — Friday August 28</h2>
                </div>
            </header>

            <!-- Nav -->
            <nav id="nav">
                <ul>
                    <li><a href="#intro" class="active">Introduction</a></li>
                    <li><a href="#schedule">Schedule</a></li>
                    <li><a href="#speakers">Speakers</a></li>
                    <li><a href="#info">Organizers</a></li>
                </ul>
            </nav>

            <!-- Main -->
            <div id="main">
                <!-- Introduction -->
                <section id="intro" class="main">
                    <header class="major" style="text-align:center">
                        <h2>Summary</h2>
                    </header>
                    <div class="spotlight" style = "width: 90%">
                        <div class="content">
                            <p>The year 2020 has seen major advances in self-supervised representation learning, with many new methods reaching high performances on standard benchmarks. Using better losses and augmentation methods, this trend will surely continue to slowly advance the field. However, it is also apparent that there are still major unresolved challenges and it is not clear what the next step-change is going to be. In this half-day workshop we want to highlight and provide a forum to discuss potential research direction seeds from radically new self-supervision tasks to downstream self-supervised learning and semi-supervised learning approaches. </p>

                            <p>As the methods are maturing, the field is now at the point where we have to start discussing how we can make optimal use of self-supervised representations in applications, as well as what are the remaining obstacles and possible approaches to tackle them. The workshop aims to give space to ask and discuss fundamental, longer-term questions with  researchers that are leading this area. Key questions we aim to tackle include:</p>

                            <ul>
                                <li> What can be learned by the current generation of self-supervised techniques? And what does, instead, still require manual supervision? </li>
                                <li> How can we make optimal use of self-supervised learning?</li>
                                <li> Is combining tasks the new way forward?</li>
                                <li> Are images enough? Video and multi-modal data as self-supervision is becoming popular. </li>
                                <li> Why do contrastive losses work well and do they scale?</li>
                                <li> How do we evaluate the quality of the learned representations?</li>
                                <li> How can we move to meaningful down-stream tasks that benefit from feature learning?</li>
                                <li> Why do methods such as clustering or contrastive losses work better than those that focus on interpretable, image-specific tasks as for example colorization or jigsaw puzzles?</li>
                            </ul>

                        </div>
                    </div>
                </section>

                <section id="speakers" class="main special">
                    <header class="major" style="text-align:center">
                        <h2>Speakers</h2>
                    </header>
                    <div class="table-wrapper" style ="width:100%">
                        <table cellpadding = "0" cellspacing = "0">
                            <tr>
                                <td><img class="rounded-img-dark" height="125px" src="photos/doersch.jpg"><br><a href="http://www.carldoersch.com/">Carl Doersch<br>DeepMind</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/efros.jpg"><br><a href="https://people.eecs.berkeley.edu/~efros/">Alexei (Alyosha) Efros<br>UC Berkeley</a></td>
				                        <td><img class="rounded-img-dark" height="125px" src="photos/favaro.jpg"><br><a href="https://www.inf.unibe.ch/about_us/people/prof_dr_favaro_paolo/index_eng.html">Paolo Favaro<br>Univ. of Bern</td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/misra.jpg"><br><a href="https://imisra.github.io/">Ishan Misra<br>FAIR</a></td>
                            </tr><tr>
                                <td><img class="rounded-img-dark" height="125px" src="photos/oord.jpg"><br><a href="https://avdnoord.github.io/homepage/">Aäron van den Oord<br>DeepMind</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/pathak.jpg"><br><a href="https://people.eecs.berkeley.edu/~pathak/">Deepak Pathak<br>CMU</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/yu.jpg"><br><a href="https://www1.icsi.berkeley.edu/~stellayu/">Stella Yu<br>UC Berkeley</a></td>
                                <td><img class="rounded-img-dark" height="125px" src="photos/zisserman.jpg"><br><a href="https://www.robots.ox.ac.uk/~az">Andrew Zisserman<br>Oxford</td>
				                    </tr>
                        </table>
                    </div>
                </section>

                <section id="schedule" class="main special">
                    <header class="major" style="text-align:center">
                        <h2>Schedule</h2>
                    </header>
                    <div class="table-wrapper" style ="width:100%">
                        <table class="alt">
                            <tbody>
                                <col width="25%">
                                <col width="60%">
                                <col width="15%">
                                <tr>
                                    <td>Welcome</td>
                                    <td></td>
                                    <td><a href="https://www.youtube.com/playlist?list=PL53R9Jy9Cc0zdv9OqvJ5YsZH2-AMKo9gM" target="_blank">&#127909; playlist</a></td>
                                </tr>
                                <tr>
                                    <td>Aäron van den Oord</td>
                                    <td>
                                        <button type="button" class="collapsible">Next Challenges for Self-Supervised Learning</button>
                                        <div class="collapsible_content"><p>TBD</p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=jJozjCG8Cqs" target="_blank">&#127909; recording</a></td>
                                </tr>
                                <tr>
                                    <td>Paolo Favaro</td>
                                    <td>
                                        <button type="button" class="collapsible">Perspectives on Unsupervised Representation Learning</button>
                                        <div class="collapsible_content"><p>Unsupervised representation learning is becoming a practical and effective approach to avoid massive labeling of data. Recent methods based on self-supervised learning have shown remarkable progress and are now able to build features that are competitive with features built through supervised learning. However, it is still unclear why some methods perform better than others. I will give an overview of methods that have been proposed in the literature and provide some analysis to try and understand what factors might be importantin the design of the next generation of self-supervised learning methods. </p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=APwHDZZcLuY" target="_blank">&#127909; recording</a></td>
                                </tr>
                                <tr>
                                    <td>Carl Doersch</td>
                                    <td>
                                        <button type="button" class="collapsible">Learning and transferring visual representations with few labels</button>
                                        <div class="collapsible_content"><p>When encountering novelty, like new tasks and new domains, current visual representations struggle to transfer knowledge if trained on standard tasks like ImageNet classification.  This talk explores how to build representations which better capture the visual world, and transfer better to new tasks.  I'll first discuss Bootstrap Your Own Latent (BYOL), a self-supervised representation learning algorithm based on the 'contrastive' method SimCLR.  BYOL outperforms its baseline without 'contrasting' its predictions with any 'negative' data; I'll provide a new perspective on why this avoids a collapse to a trivial solution.  Second, I'll present CrossTransformers, which achieves state-of-the-art few-shot fine-grained recognition on Meta-Dataset, via a self-supervised representation that's aware of spatial correspondence.</p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=RWCc0nZOSBw" target="_blank">&#127909; recording</a></td>
                                </tr>
                                <tr>
				                            <td>Andrew Zisserman</td>
                                    <td>
                                        <button type="button" class="collapsible">Beyond Self-Supervised Representation Learning</button>
                                        <div class="collapsible_content"><p>The talk will describe three phases of self-supervised learning. First, the `classical' phase, where the goal is semantic representation learning, e.g. training a network on ImageNet for an image representation. The second, `expansion' phase goes beyond single modality representation learning. The goals are more general and cover classical computer vision tasks, such as tracking and segmentation; and the data can be multi-modal such as video with audio. Tasks here include learning joint embeddings, learning to localize objects, and learning to transform videos into discrete objects. The final `uncurated' phase involves self-supervised learning from  uncurated data.</p></div>
                                    </td>
                                    <td></td>
                                </tr>
                                <tr>
                                    <td>Ishan Misra</td>
                                    <td>
                                        <button type="button" class="collapsible">Multi-view invariance and grouping for self-supervised learning</button>
                                        <div class="collapsible_content"><p>In this talk I will present our recent efforts in learning representation learning that can benefit semantic downstream tasks. Our methods build on two simple yet powerful insights - 1) The representation must be stable under different data augmentations or "views" of the data; 2) The representation must group together instances that co-occur in different views or modalities. I will show that these two insights can be applied to weakly supervised and self-supervised learning, to image, video, and audio data to learn highly performant representations. For example, these representations outperform weakly supervised representations trained on billions of images or millions of videos; can outperform ImageNet supervised pretraining on a variety of downstream tasks; and have led to state-of-the-art results on multiple benchmarks. These methods build upon prior work in clustering and contrastive methods for representation learning. I will conclude the talk by presenting shortcomings of our work and some preliminary thoughts on how they may be addressed.</p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=gbziPIn9uDI" target="_blank">&#127909; recording</a></td>
                                </tr>
                                <tr>
                                    <td>Stella Yu</td>
                                    <td>
                                        <button type="button" class="collapsible">Representation Learning beyond Instance Discrimination and Semantic Categorization</button>
                                        <div class="collapsible_content"><p>Unsupervised representation learning has made great strides with invariant mapping and instance-level discrimination, as benchmarked by classification on common datasets.  However, these datasets are curated to be distinctive and class-balanced, whereas naturally collected data could be highly correlated within the class and long-tail distributed across classes.  The natural grouping of instances conflicts with the fundamental assumption of instance-level discrimination. Contrastive feature learning is thus unstable without grouping, whereas grouping without contrastive feature learning is easily trapped into degeneracy.  By integrating grouping into a discriminative metric learning framework, I will show that we can not only outperform the state-of-the-art on various classification, transfer learning, semi-supervised learning benchmarks with a much smaller (academic :-) compute, but also extend the goal of representation learning beyond semantic categorization.</p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=F5mt4z-w_Mk" target="_blank">&#127909; recording</a></td>
                                </tr>
                                <tr>
                                    <td>Alexei (Alyosha) Efros</td>
                                    <td>
                                        <button type="button" class="collapsible">Self-supervision as a path to a Post-dataset Era</button>
                                        <div class="collapsible_content"><p>TBD</p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=iTbfEXFwDJc" target="_blank">&#127909; recording</a></td>
                                </tr>
                                <tr>
                                    <td>Deepak Pathak</td>
                                    <td>
                                        <button type="button" class="collapsible">Self-Supervision and Modularity: Cornerstones for Generalization in Embodied Agents</button>
                                        <div class="collapsible_content"><p>TBD</p></div>
                                    </td>
                                    <td><a href="https://www.youtube.com/watch?v=fUMpC_hoedA" target="_blank">&#127909; recording</a></td>
                                </tr>
                        </tbody>
                      </table>
                  </div>
                </section>
						
                <section id="info" class="main special">
                    <header class="major">
                        <h2>Organizers</h2>
                    </header>
                    <div class="table-wrapper" style ="width:100%">
                        <table cellpadding = "0" cellspacing = "0">
                            <tr>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/rupprecht.jpg"><br><a href = "http://chrirupp.github.io">Christian Rupprecht<br>University of Oxford</a></td>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/asano.jpg"><br><a href = "https://yukimasano.github.io/">Yuki M Asano<br>University of Oxford</a></td>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/joulin.jpg"><br><a href = "https://scholar.google.fr/citations?user=kRJkDakAAAAJ&hl=en">Armand Joulin<br>FAIR</a></td>
                                <td><img class = "rounded-img-dark" height = "125px" src = "photos/vedaldi.jpg"><br><a href = "https://www.robots.ox.ac.uk/~vedaldi">Andrea Vedaldi<br>University of Oxford</td>
                            </tr>
                        </table>
                    </div>
                </section>
            </div>

                 
            <!-- Footer -->
            <footer id="footer">
                <p class = "copyright" style="font-size:medium">
                    Website design adapted from <a href = "http://sightsound.org">sightsound.org</a>
                    and based on a template from <a href="https://html5up.net">HTML5 UP</a>.
                </p>
            </footer>
			</div>

		<!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/skel.min.js"></script>
        <script src="assets/js/util.js"></script>
        <!--[if lte IE 8]>
        <script src="assets/js/ie/respond.min.js"></script><![endif]-->
        <!-- <script src="assets/js/main.js"></script> -->
    <script>
      function convertDateAndTimezone(timeStr) {
        var newDate = new Date("2020-08-28T"+timeStr+":00.000Z");
        return newDate.toString();   
      }
      
	    function convertTime(timeStr) {
        var newDate = new Date("2020-08-28T"+timeStr+":00.000Z");
        return newDate.toLocaleTimeString([], {hour: '2-digit', minute:'2-digit'});   
      }
      
      function convertTimeRange(rangeStr) {
        var s = rangeStr.split('-')
        return convertTime(s[0]) + ' - ' + convertTime(s[1]);   
      }
      
      $( document ).ready(function() {
        $( ".convertTime" ).each(function( index ) {
          $(this).text(convertTime($(this).text()));
        });

        $( ".convertDate" ).each(function( index ) {
          $(this).text(convertDateAndTimezone($(this).text()));
        });

        $( ".convertTimeRange" ).each(function( index ) {
          $(this).text(convertTimeRange($(this).text()));
        });
        
        $( ".collapsible" ).click(function() {
            $(this).toggleClass("active");
            $(this).next().toggle();
        });
      });
	  </script>
	</body>
</html>
